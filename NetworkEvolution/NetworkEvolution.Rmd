---
title: "Influencing Factors on Social Network Evolution"
author-inputfile: "anonauthors.tex" 
abstract: |
  The abstract should briefly summarize the contents of the paper in 150--250 words.
keywords: "First keyword \\and Second keyword \\and Another keyword."
bibliography: ["rpackages.bib", "bibliography.bib"]
biblio-style: "apalike"
link-citations: true
output:
  pdf_document:
    fig_caption: true
    keep_tex: true
    template: lncs-template.tex
    md_extensions: +footnotes
    citation_package: biblatex
    dev: pdf
    
---


```{r knitr_init, echo=FALSE, message=FALSE, warning=FALSE, cache=FALSE, paged.print=TRUE}
## Global options
library(knitr)
#options(max.print="75")
opts_chunk$set(echo=FALSE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE,
               out.width='100%'
               )
opts_knit$set(width=100)

# Load required libraries
library(rmdformats)
library(tidyverse)
library(cowplot)
# add libraries here

# Add libraries to cite here:
pkgs <- c("knitr", "tidyverse", "rmdformats", "kableExtra", "scales", "psych", "rmdtemplates")
rmdtemplates::write_bib(pkgs)
```


# Introduction
In the past decade the evolution of the internet and social media platforms raised new forms of social networks that changed our interpersonal communication and the methods of information procurement considerably. It has become very easy to connect to existing friends online, look for new friends and exchange information with them for example using platforms like Facebook or Twitter. As the formation of an individual's opinion is based on all available resources it is important to understand how the information received in online social networks is embedded into the process of opinion formation and how people behave in such networks. 

# Theory
Existing research states that the vast availability of similar-minded people in online social networks leads us to enclose ourselves in so-called echo chambers and to disconnect from people who are too different from us. This leads us to reinforce our opinion solely through finding others that think similar. If this reinforcement would continue, people would be separated into different camps quickly and would not be able to agree on each other anymore. As most people prefer to make compromises it is interesting to have a closer look on the thresholds which let them keep in touch with people who they donâ€™t agree on and how a variation of these thresholds changes the overall picture. Therefore, we created an agent-based model that allows us to simulate the desired behaviors and to compare the resulting network structures.

To reproduce an online social network in a simulation we must rely on a network generator that is comparable to a real network. As social media platforms such as Facebook and Twitter are close to a scale-free network in their overall network structure and follow a powerlaw distribution, the Barabasi-Albert network generator is most suitable for generating a realistic network topology. Within a Barabasi-Albert network there exists a little amount of very well-connected hubs while most nodes have only few connections to others. The Barabasi-Albert generator provides several parameters like the initial network size, the number of new nodes that are added to an initial network and the number of edges which are created by the joining nodes to existing nodes using preferential attachment. This allows us to get the simulation close to a real social network structure.

# Method
We chose the programming language Julia to conduct our research. With the LightGraphs package, this language provides performant network simulation and the required network generators for our agent-based model. It is also possible to implement batch runs that are based on the same random seed so that the network evolution following different parameters can be analyzed subsequently.

In our research, we focused on the variation of limited parameters for answering our research questions:

-	Size of the network: How do network and opinion dynamics interplay with the size of a social network?
-	Adding friends: What is the difference between randomly making friends in the network and choosing only from the friends of existing friends?
-	Removing friends: How does the threshold for accepting opinion differences interfere with the overall opinion and network dynamics?
The distribution of opinions throughout the agents was not varied, but uniformly distributed, because their variation would have blurred the effect of the examined parameters on the network evolution.

To analyze the effect of our parameters, we chose different approaches of social network analysis and evaluated the resulting networks and their nodes regarding their degree, centrality, communality, diameter, and clustering coefficient.

## Network analysis
Chosen measures:

- Density
- In-/Outdegree Mean, SD and Maximum
- Closeness centrality mean + max
- Betweenness centrality mean + max
- Clustering coefficient mean
- Number of Communities found through label propagation algorithm
- Connected components

## Analysis of opinion dynamics

We looked on multiple measures to detect the effect of network structure and the investigated factors on opinion dynamics in the network:

- Opinion SD
- Opinion Change Delta Mean (Opinion Change from initial to final opinion of an agent)
- Supernode Opinion
- SD of Disctinct communities opinion means

The measures were all calculated for the final state of the simulation runs and averaged over all repetitions of the same run so that we are able to prove differences between the simulation runs.

## The Network Model
We designed a network in which agents interact with each other through publishing posts to their followers and receiving content through their followees. The network is directed so that it is more suitable to represent a real online social network as currently most of the famous social networks allow for unidirectional relationships. The different edges are considered as direction of information spread: outgoing edges from agent x show to which agents the posts of agent x will be sent while incoming edges show from which agents the agent x receives posts. The initial network is created by using the Barabasi Albert Network generator of the LightGraphs package in Julia. This generator allows to define the size of the network and an initial average edge count per agent that follows a power law distribution.

After creating the network, the agents are generated with the following attributes:

- Opinion [-1,1]: Main attribute to change their network of incoming edges (followees). Initially, the opinion is uniformly distributed over all agents.
- Perceived Public Opinion [-1,1]: The mean opinion a particular agent perceives in its neighborhood through seeing the posts of inneighbors. If the absolute distance between the public and its own opinion is in a defined threshold, the agent approaches towards the public opinion. If not, the agent will move into the opposite direction of the perceived opinion (therewith increasing the distance). If an agent ends up having no neighbors, the perceived public opinion mirrors its own opinion.
- Inclination to Interact [0,Inf]: The willingness of agents to share posts. A distribution function sets 80% of the agents to passive receivers who rarely share a post. Very few agents have a higher inclination to interact than 1 and share multiple posts per simulation step. After initial generation, this attribute is fixed.
- Feed (Array of max. 15 posts): Storage of received posts. The feed of agent x contains all shared posts from agents who are inneighbors of agent x

The perceived public opinion is the only factor that has influence on an agent's opinion and is driven by the posts that are visible to this agent. The most important attributes of a post are:

- Opinion [-1,1]: A post's opinion is generated from the opinion of the agent who publishes it. Its opinion is randomly varied by applying a random addition between [-0.1,0.1].
- Weight: The weight of a post represents the publicity of an agent as it is the count of outneighbors of the posting agent. Posts with high weights are perceived as more important and influential through the receiving agents compared to posts that have been published from agents with low outdegree.

## The Simulation Architecture
A simulation consists of an initiating phase that creates the required initial network and agents with their properties, a main simulation phase where the agents interact and time steps are performed and a data saving phase. Every simulation timestep follows the same order of actions. First, the agent list is shuffled to ensure that the order in which the agents perform their interactions don't have an impact on the simulation outcomes. Following, the actions of a certain agent in a simulation step are described:

1. *Update the feed:* The posts that were received in the previous step get sorted by their weight and the weight of all posts in the feed are reduced by the factor 0.5 to provide higher visibility to newer posts. The feed is limited to the 15 highest-weighted posts, all other posts are dropped and not further considered for calculation of the perceived public opinion.
2. *Update perceived public opinion:* The updated feed is used to calculate the perceived public opinion. The opinion of posts with higher weights have a higher influence in calculation. If the feed of the agent is empty, the perceived public opinion mirrors the opinion of the agent.
3. *Update the opinion:* With the perceived public opinion an agent now updates its own opinion. If the absolute distance between public opinion and own opinion is inside a defined threshold, the agent approaches towards the public opinion by a factor of 0.05. If the absolute distance lies outside the range, the agent moves into the opposing direction and therewith increases the distance what we call the "backfire effect".
4. *Drop ingoing edges:* With regarding its updated opinion, an agent checks if the current posts in his feed are in an accepted absolute distance to the own opinion. If not, the agent also checks the real opinion of the source agent and if this opinion is also outside the accepted range, the agent drops the incoming edge so that it won't receive further posts of the former followee. In one step, an agent can only drop a tenth of his current number (rounded up) of ingoing edges so that a realistic behavior is maintained.
5. *Add ingoing edges:* After disconnecting from agents that are outside of the accepted opinion range, an agent adds new ingoing edges if his inneighbors count is below a desired value. All agents try to maintain an indegree that equals a tenth of the network size. Adding edges is based on the configuration either done by selecting candidates from the neighbors of the agent's inneighbors without regarding the opinion or selecting candidates randomly from the whole network that lie inside a defined absolute distance from the own opinion. In the third configuration both approaches are combined. From the selected candidates, an agent always chooses the one with the highest outdegree first and creates a new directed edge towards itself. This process is continued until the number of new inneighbors is reached or the list of candidates is empty.
6. *Publish posts:* When the network maintenance is finished, an agent starts to publish posts with regard to its inclination to interact. A post is generated through multiplying the own opinion with a randomly chosen factor in [-0.1,0.1] and setting the post weight equals to the own current outdegree. After generating the post it is shared to all feeds of the current agent's outneighbors.

The beforehand described actions are performed by every agent during a simulation step. After all agents are finished, their current states and network measures are logged for analysis. After all steps are done, the simulation object is saved containing the initial and final state, intermediate states at each 10% of the simulation, agent and post logs and the configuration of the certain run.


# Results
We performed in total 13 different simulation runs that cover the following variations of factor configuration:

- Network Size in 100, 200, 300, 400, 500 Agents
- Addfriends Method as Neighbors of Neighbors, hybrid and random
- Unfriend Threshold of 0.4, 0.6, 0.8, 1.0, 1.2

This allows us to examine subsequently the influence of the factor levels seperately. Each distinct simulation configuration was repeated 100 times to clear out effects that are due to usage of random numbers in the simulations.



## Impact of Network Size
- Density of network decreases with higher net size
- Outdegree/Indegree SD increases
- Closeness Centrality increases
- Betweenness Centrality decreases
- Clustering Coefficient decreases
- Community Count increases
- OpinionSD increases
- OpinionSD of Top10 Nodes increases


## Impact of Unfriend Threshold

- With higher Unfriend Threshold the overall edgecount increases
- also does Outdegree/Indegree AVG and SD
- Closeness Centrality increases with higher unfriend threshold
- Clustering Coefficient shows no effect
- OpinionSD increases with higher unfriend threshold



- Threshold of annoyance shows direct influence on edgecount: With a higher threshold for differing opinions, edge count decreases (effect is stronger for smaller network sizes)
- With lower tolerance of differing opinions the agents become more consensual (on lowest level = 0.4, final opinion distribution has std of 0.31). This effect increases with settings that use random or hybrid picking of new friends to SD <= 0.08

- Agents can get isolated for certain reasons that depend on the addfriends mechanic: in random selection, radicalized agents have a higher probability to get isolated as they won't add new friends if all other agents' opinions are too far away. In Neighbors of neighbors, agents who disconnect from their last neighbor have no chance to get back into the network.

## Impact of the addfriends mechanic
- Edgecount is least for Neighbors of Neighbors approach, medium for hybrid and highest for random
- OutdegreeAVG is higher for hybrid and random approach, SD higher for Random and equal on hybrid and NoN
- Centrality is lowest for hybrid and equal at random and NoN approach
- Clustering Coefficient is higher for random and hybrid approach than for NoN
- OpinionSD is highest for NoN and lowest for random

## Structure follows opinion or vice versa?
For the different settings we were able to detect cases where the structure of the network influenced the individual agent's opinion formation significantly and also cases where the opinion distribution has lead to a change of network structure.

Opinion follows structure: Unfriend Threshold (Below 0.6 leads always to consensus)

Structure follows Opinion: Addfriends mechanic (NoN Approach leads to more communities and disconnected components, also higher diversity of the communities)


## Reasons to disconnect
Reasons for disconnecting from the network and staying disconnected for the rest of the simulation varied between the different configurations. While disconnected agents in networks with random or hybrid new friends picking would still be able to reconnect to others, agents who disconnected in the neighbors of neighbors setting were not able to reconnect. Complete disconnection of agents in the final state occured only in networks with an unfriend threshold of 0.4 and 0.8. It happened most often in simulations that used the neighbors of neighbors approach followed by the random approach and least often in simulations with hybrid approach of edge creation.

# Discussion
Our research provides important insight for simulating online social networks. We were able to show that the examined parameters play an important role for modelling a realistic network. The Barabasi-Albert generator proved to be a solid basis for building such simulations. Nevertheless, it is important to compare it with other generators and to enrich simulations by including more functionality like adding and removing agents to the network and experimenting with different initial opinion distributions. We will continue our work on simulating opinion and network dynamics with Julia to be able to include more parameters and to enhance the accuracy of our simulations.


#### Sample Heading (Fourth Level)
The contribution should contain no more than four levels of
headings. TableÂ \ref{tab1} gives a summary of all heading levels.

Another nice feature are shortcuts for \eg and \ie 

# References
You can cite any paper in parenthesis as following [@valdez2017priming] or inline saying that @valdez2017priming found something.
Multiple citations are possible as wellÂ [@valdez2017priming;@valdez2019users].

You can refer to other sections by kebab-casing to sectionÂ \ref{a-subsection-sample}. You can easily cite an r-package directly in the text by using the `cite_pkg` function from the package `r rmdtemplates::cite_pkg("rmdtemplates")`. 


# Environments

The environments 'definition', 'lemma', 'proposition', 'corollary', 'remark', and 'example' are defined in the LLNCS document class as well.


## Theorems
\begin{theorem}
This is a sample theorem. The run-in heading is set in bold, while
the following text appears in italics. Definitions, lemmas,
propositions, and corollaries are styled the same way.
\end{theorem}

## Equations
\begin{equation}
x + y = z
\end{equation}



## Tables
You can get the non breaking space in RStudio by pressing ALT+SPACE.
You can refer to tables by using TableÂ \ref{tab:table_1}.

```{r table_1, echo=FALSE}
# Note that the label has to be added manually in the caption here.
iris %>% head() %>% knitr::kable(caption = "Test\\label{tab:table_1}")
```


### Inline Latex Tables
You can directly add latex tables.

\begin{table}
\caption{Table captions should be placed above the
tables.}\label{tab1}
\begin{tabular}{|l|l|l|}
\hline
Heading level &  Example & Font size and style\\
\hline
Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
\hline
\end{tabular}
\end{table}


## Figures

You can refer to tables by using FigureÂ \ref{fig:fig1}.

```{r fig1, fig.cap="This is the text caption under the figure"}
# Note that the label for a figure is always fig:chunkname
iris %>% ggplot() + aes(x = Sepal.Length) + geom_histogram() + cowplot::theme_minimal_hgrid()

```



# Acknowledgements {-}
We would like to thank xyz.
We would further like to thank the authors of the packages we have used.
```{r r_citations, eval=TRUE, include=TRUE, results="asis"}
rmdtemplates::line_cite(pkgs) # This creates a single line citing all packages
#rmdtemplates::list_cite(pkgs) # This creates a "thightlist" of all packages 
```

# References
